{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7403033e-9b40-453a-8d04-43744a332db5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Assembling RADseq data with ipyrad\n",
    "\n",
    "<br>\n",
    "\n",
    "## Overview\n",
    "\n",
    "\n",
    "This Jupyter notebook covers how to assemble RADseq data from raw reads into aligned loci that can be used for downstream analyses. You will download raw data from a Google bucket and then use the ipyrad pipeline to assemble and filter these data.\n",
    "\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "1. Run ipyrad to assemble raw Illumina reads into aligned loci\n",
    "2. Use ipyrad to remove individuals outside the focal group or with high missing data\n",
    "3. Use ipyrad to filter missing data\n",
    "\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- **Python**: This notebook runs in a python kernel, although note that you will be entirely using magics to execute bash commands. You could run all of these commands in bash outside of a Jupyter notebook entirely in bash.\n",
    "- **ipyrad**: This notebook will install and use `ipyrad`\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "## Background\n",
    "\n",
    "\n",
    "Restriction site-Associated DNA sequencing (RADseq) is a high-throughput genotyping technique used in molecular biology and genomics. It is one method to generate reduced representation libraries, which allow us to prepare and sequence hundreds to thousands of genomic regions from across the genome without sequencing the entire genome. RADseq methods use restriction enzymes to cut up the genome and then sequence DNA regions that are adjacent to these cut sites. The idea is that within the same species or relatively closely related species, restriction enzyme cut sites should mostly be at the same places and allow for the selection of shared loci across samples without needing to develop sepecific probes.\n",
    "\n",
    "Because RADseq approaches use restriction enzyme cut sites to select for shared loci among samples, they are a great choice any time that researchers want to genotype non-model organism samples for thousands of independend loci. RADseq is very common in evolutionary biology, but RADseq methods can be used in a wide array of applications, including studying [tumor evolution](https://pubmed.ncbi.nlm.nih.gov/28611298/).\n",
    "\n",
    "\n",
    "\n",
    "One of the most commonly used RADseq approaches, and the one that we'll use here, is double digest RADseq (ddRADseq) which uses two enzymes to cut up the genome and then a size selection step to further reduce the total set of total set of loci, which should ideally result in fewer loci that require less sequencing effort and that overlap among samples.\n",
    "\n",
    "\n",
    "This figure from [(Peterson et al. 2012)](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0037135) shows how sequencing is targeted at specific reginos by RADseq and ddRADseq approaches:\n",
    "\n",
    "<img src=\"images/ddrad_peterson.png\" width=50% />\n",
    "\n",
    "\n",
    "There are various other RADseq approaches, including the original formulation of RADseq that used a single enzyme and no size selection, as described [here](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0003376) or 3RAD which incorporates an extra enzyme to cut apart adapter dimers as descibed [here](https://peerj.com/articles/7724/). Use of different strategies, restriction enzymes, and size selection windows will affect what loci you target from your organisms of interest, and the best strategy will depend on genomic properties of your target organism and your desired sequencing effort.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "We’ll be working with empirical double digest RADseq data  that I (Sean Harrington) generated as part of my PhD research. The data are for a species of rattlesnake, the red diamond rattlesnake (*Crotalus ruber*), that is distributed across the Baja California peninsula and into southern California. \n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/ruber.jpg\" width=50% />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "I was interested in identifying if there is any population structure in *C. ruber* and inferring what population genetic and environmental forces have resulted in any existing structure. The data are single-end reads generated on an Illumina hiSeq. My analyses of these data are published in [Harrington et al. 2018](https://onlinelibrary.wiley.com/doi/full/10.1111/jbi.13114).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The dataset is reasonably small and we should be able to quickly process and analyze it.\n",
    "\n",
    "We will use [ipyrad](https://ipyrad.readthedocs.io/en/master/) to process and assemble the raw data into alignments. ipyrad is a flexible python-based pipeline for taking various types of restriction-site associated data, processing them, and generated aligned datasets.\n",
    "\n",
    "ipyrad is capable of generating datasets either by mapping your raw reads to a reference genome or using a de novo assembly method that does not require a reference. We will use the de novo method here.\n",
    "\n",
    "If you need help with ipyrad, you can always post [here](https://app.gitter.im/#/room/#dereneaton_ipyrad:gitter.im). The developers are very responsive to queries.\n",
    "\n",
    "ipyrad is certainly not the only option for assembling RADseq data. [Stacks](https://catchenlab.life.illinois.edu/stacks/) and [dDocent](https://www.ddocent.com//) are other popular options, or there are various ways to manually assemble or map RADseq data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will be using a python kernel throughout this tutorial, but all commands will be bash commands, and so will be preceded by `!`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4bceeb-c68d-4eac-a490-05b4751ce766",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyterquiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f0e93b-f231-4f66-a3a2-3eced485b46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyterquiz import display_quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009069f0-bf36-4723-b83e-1f75699d6017",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "# Get started\n",
    "\n",
    "<br>\n",
    "\n",
    "## Files and basic setup\n",
    "\n",
    "The files we will use are:\n",
    "\n",
    "- all_ruber.fastq\n",
    "- barcodes_samples.txt\n",
    "- names_ruber_all.txt\n",
    "\n",
    "We will copy these from the google bucket for this tutorial into your GCP instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ee98a-a4a8-4ec6-97de-c3468a53a164",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gsutil -m cp -r gs://radseq_cloud/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990df80-df0a-4e4a-a738-4e2ea53c68a6",
   "metadata": {},
   "source": [
    "## fastq format\n",
    "\n",
    "Before we start doing anything with the data, it's worth seeing what the raw data looks like. The standard format of raw genomic sequence data is fastq.\n",
    "\n",
    "Let's take a look at the first 8 lines of the fastq file. The following command will help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0784010f-23fc-4c4a-ad8e-ef83163a90df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! zcat radseq_cloud/ruber_data/all_ruber.fastq.gz | head -n 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada408c5-c69f-4aa9-b5b9-0388c93bd757",
   "metadata": {
    "tags": []
   },
   "source": [
    "- note that these reads are gzipped (compressed; end in .gz): you cannot directly look at them with `head` but instead need to use `zcat`, which reads gzipped files, and pipe the output to `head`. Fastq files are typically gzipped to save disk space, and most genomics programs can read gzipped fastqs.\n",
    "\n",
    "You should see this:\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Click to show expected fastq</summary>\n",
    "  <img src=\"images/fastq.png\" width=70% />\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "Each read from the sequencer is represented by four lines. For example, the first four lines correspond to the first read, the next four lines to the second read, and so on. Here's the breakdown of each line for a single read:\n",
    "\n",
    "1. **Line 1 (Header)**:  \n",
    "   This line always begins with `@` and contains the sequence identifier along with optional information about the read, such as details about the sequencing run.\n",
    "  \n",
    "2. **Line 2 (DNA Sequence)**:  \n",
    "   This line contains the actual DNA sequence of the read, represented as a string of nucleotide bases (A, T, C, G).\n",
    "\n",
    "3. **Line 3 (+ Separator)**:  \n",
    "   This line starts with a `+` and may either be empty or contain additional information, such as the sequence identifier again. This line serves primarily as a separator.\n",
    "\n",
    "4. **Line 4 (Quality Scores)**:  \n",
    "   This line contains the quality scores for each base in the DNA sequence. The number of characters in this line matches the length of the sequence from Line 2. Each character corresponds to the quality score for the respective base in the sequence (e.g., the 4th character in this line represents the quality of the 4th base in the sequence).\n",
    "\n",
    "This structure repeats for each read in the FASTQ file.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902e686d-b575-4275-abf5-59b51f9f5537",
   "metadata": {},
   "source": [
    "\n",
    "### Installing ipyrad\n",
    "\n",
    "Next up, we'll use mamba to install ipyrad. If mamba is not already installed, you can do so with: \n",
    "```\n",
    "# Download the latest Mambaforge installer\n",
    "! curl -fL -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\n",
    "\n",
    "# Install Mambaforge without output\n",
    "! bash Miniforge3-$(uname)-$(uname -m).sh -b -p $HOME/miniforge3 > /dev/null 2>&1\n",
    "# If you want to see all the output you can remove `> /dev/null 2>&1` which redirects output so that we don't see it\n",
    "\n",
    "\n",
    "# Add the Miniforge bin directory to the system PATH environment variable\n",
    "import os\n",
    "os.environ[\"PATH\"] = os.environ[\"HOME\"] + \"/miniforge3/bin:\" + os.environ[\"PATH\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf95e68a-125b-42cf-bb9d-3a019ff3840e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify that mamba/conda is available in the PATH\n",
    "! mamba --version\n",
    "\n",
    "# Use mamba to install ipyrad - similarly without output using `> /dev/null 2>&1`\n",
    "! mamba install ipyrad -c conda-forge -c bioconda -y > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9428fbb7-8628-4fee-8434-41c2f949fc5f",
   "metadata": {},
   "source": [
    "## Running iPyRad\n",
    "\n",
    "\n",
    "### Generating a params file\n",
    "\n",
    "\n",
    "First, we need to generate a params file that contains the parameters we need to specify for ipyrad. In your scripts directory, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d27bc2-55db-474f-97e4-25782a6a836c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ipyrad -n ruber_denovo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed742b9-61b6-44b1-b564-df0d16181796",
   "metadata": {},
   "source": [
    "This will create a params file with the defaults that ipyrad uses, we can modify these as we need. Whatever comes after the -n is what the assembly will be named\n",
    "\n",
    "<br>\n",
    "\n",
    "- **Note that if you ever need to overwrite output from ipyrad, e.g., to overwrite an existing prams file with a fresh one of the same name, or to overwrite partial ouput that failed, you will need to add a `--force` flag to the end of your ipyrad command. If you do not include the --force flag and try to run a step that will overwrite existing output, ipyrad will tell you that output already exists.**\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Editing the params file\n",
    "\n",
    "\n",
    "Let’s go look at that and edit it. You can directly use the editor that the JupyterLab interface provides. In the left pane, if it's not already open and active, click on the folder icon, then double click the \"params-ruber_denovo.txt\" file, and it will open in a text editor.\n",
    "\n",
    "<img src=\"images/params_file_location.png\" width=50% />\n",
    "\n",
    "\n",
    "In the editor that opens up, I uncheck \"Wrap Words\" from the \"View menu\" so that each line of code stays on a single line.\n",
    "\n",
    "\n",
    "**We’ll change a few of these parameters:**\n",
    "\n",
    "- [1]: This is where output will be written, edit this to `/home/jupyter/RADseq_cloud_learn/ipyrad_out`\n",
    "\n",
    "- [2]: this needs to reflect the path to the `all_ruber.fastq.gz` file, which is: `/home/jupyter/RADseq_cloud_learn/radseq_cloud/ruber_data/all_ruber.fastq.gz`\n",
    "\n",
    "- [3]: this needs to be the path to `barcodes_samples.txt`: `/home/jupyter/RADseq_cloud_learn/radseq_cloud/ruber_data/barcodes_samples.txt`\n",
    "\n",
    "- [7]: dataype should be `ddrad`\n",
    "\n",
    "- [8]: restriction overhang is: `TGCAGG, GATC` these are the overhangs created by the restriction enzymes for ddRAD that was used for these data. These can be difficult to find and is covered in the ipyrad params documentation\n",
    "\n",
    "- [14]: This is the clustering threshold for clustering reads into loci within samples. This is an important paramater that can have large effects on your final dataset. The default of `0.85` is good for phylogenetic datasets, but for population genetics, you will often want to use a higher threshold like 0.9 or 0.93. Let's use `0.9` here.\n",
    "\n",
    "- [27]: change to `*`, this will generate all output formats that ipyrad is currently capable of\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "You can either change these manually or use the following code cell to make these replacements using `sed`. \n",
    "\n",
    "**If you use the sed commands in the next cell, you should still examine the params file before and after the changes to make sure you know what paramaters are being set. These parameters can have dramatic impacts on your data na downstream analyses, and you should not always use the values that we use here**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009a3e3d-5f9f-4411-acf8-82508c31d8fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make these parameter replacements programmatically:\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[1\\] \\[project_dir\\]:.*|/home/jupyter/RADseq_cloud_learn/ipyrad_out        ## [1] [project_dir]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[2\\] \\[raw_fastq_path\\]:.*|/home/jupyter/RADseq_cloud_learn/radseq_cloud/ruber_data/all_ruber.fastq.gz        ## [2] [raw_fastq_path]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[3\\] \\[barcodes_path\\]:.*|/home/jupyter/RADseq_cloud_learn/radseq_cloud/ruber_data/barcodes_samples.txt        ## [3] [barcodes_path]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[7\\] \\[datatype\\]:.*|ddrad                   ## [7] [datatype]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[8\\] \\[restriction_overhang\\]:.*|TGCAGG, GATC        ## [8] [restriction_overhang]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[14\\] \\[clust_threshold\\]:.*|0.9                    ## [14] [clust_threshold]:|' params-ruber_denovo.txt\n",
    "\n",
    "! sed -i 's|^\\([^#]*\\)## \\[27\\] \\[output_formats\\]:.*|*                      ## [27] [output_formats]:|' params-ruber_denovo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f964b8e-410b-48c2-ba3c-47bba04ab2ba",
   "metadata": {},
   "source": [
    "\n",
    "The rest of these paramaters are at generally reasonable values, although depending on your data, you may want to modify some of these. \n",
    "\n",
    "**The parameters are all well documented [here](https://ipyrad.readthedocs.io/en/latest/6-params.html).** We highly recommend that you spend some time familiarizing yourself with these parameters and what steps they are important in.\n",
    "\n",
    "* For our final dataset, we'll want to set parameter [21] \"min_sample per locus\" to something higher to end up with a reasonable amount of missing data, but we'll deal with this later.\n",
    "\n",
    "Your final file should look like this (also showing the view menu where you can uncheck \"Wrap Words\"):\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "  <summary>Click to show edited params file</summary>\n",
    "  <img src=\"images/edited_params.png\" width=100% />\n",
    "</details>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "Close out of that file and save when prompted.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "### Running the first 5 steps\n",
    "\n",
    "\n",
    "We'll start by running steps 1-5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8507e3d-f742-4630-8014-c2938474b492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run ipyrad with those parameters for steps 1-5 and using 8 cores\n",
    "! ipyrad -p params-ruber_denovo.txt -s 12345 -c 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b250661-b1d8-4e68-ae3e-c8da8fc4723e",
   "metadata": {},
   "source": [
    "This should take around 20 minutes. While that's running, familiarize yourself with the steps in ipyrad, which are thoroughly documented [here](https://ipyrad.readthedocs.io/en/master/7-outline.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f38d06-2454-429a-92fe-137577c68a56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_quiz(\"quizzes/submodule_1/quiz1.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148fee7-33ac-4bf2-a37e-fc34ce5e395d",
   "metadata": {},
   "source": [
    "## Branching an assembly\n",
    "\n",
    "We only completed steps 1–5 in the process outlined above because the initial FASTQ file contains primarily *Crotalus ruber* (red diamond rattlesnakes) individuals, but also a few representatives from other rattlesnake species included as outgroups. \n",
    "\n",
    "- Steps 1–5 assemble loci within individual samples, but they do not yet involve alignment across individuals. \n",
    "\n",
    "**At this stage, our goal is to generate a dataset containing only *C. ruber* individuals for subsequent population genomics analyses in the next session**. After we remove the outgroup individuals from the dataset, we will execute the final steps to create the necessary alignments across individuals.\n",
    "\n",
    "The ipyrad pipeline offers functionality to create new \"branches\" of the assembly using different parameters, such as including or excluding specific individuals. We will use this capability to isolate the desired individuals for our analysis.\n",
    "\n",
    "<br>\n",
    "\n",
    "### Make a branch with only samples of interest:\n",
    "\n",
    "If we wanted to include all samples in the dataset, we could have run all seven steps in a single process.\n",
    "To create a new branch containing only the selected individuals, follow these steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f143598-1bf3-402e-b637-87bc6a3ef0a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# branch the assembly\n",
    "! ipyrad -p params-ruber_denovo.txt -b ruber_only_denovo radseq_cloud/ruber_data/names_ruber_all.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbe72cd-1e3c-4a93-b6e7-8d6f2d49882f",
   "metadata": {},
   "source": [
    "This will use our old assembly and params file to generate a new branch, with params file `params-ruber_only_denovo.txt` that includes only samples in the `names_ruber_all.txt file`.\n",
    "\n",
    "**We need to further edit this file to change parameter [21] “min_sample per locus”**. The parameter defines how many how many individual samples a locus must have data for to include that locus in the final dataset. It controls the amount of missing data in the final dataset. Here, let's set this to `26` - this is about 75% of individuals and should result in a matrix that is ~75% or greater complete.\n",
    "\n",
    "**As we did for the \"params-ruber_denovo.txt\", open the new \"params-ruber_only_denovo.txt\" file in the text editor and make this change:**\n",
    "\n",
    "`26               ## [21] [min_samples_locus]: Min # samples per locus for output`\n",
    "\n",
    "You could also make this change using a sed command, but again, we recommend at least looking at the params file again here and re-familiarizing yourself with the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1c34c-241c-42d1-ad34-25e276cb3dca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! sed -i 's|^[^#]*## \\[21\\] \\[min_samples_locus\\]:|26                    ## [21] [min_samples_locus]:|' params-ruber_only_denovo.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8150f5e-92f5-4277-bc45-eac24e137dd5",
   "metadata": {},
   "source": [
    "Once that change has been made, save and close the file, then run the final 2 steps in ipyrad. This should be fast and take just a minute or two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556df84a-d2e6-4e40-9dae-64c81409535d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! ipyrad -p params-ruber_only_denovo.txt -s 67 -c 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdd6c2d-7431-47dd-b438-d6d3c834602a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examining the output\n",
    "\n",
    "\n",
    "Before you start analyzing your data, you should always take a look at the output stats.\n",
    "\n",
    "Navigate to the `ipyrad_out/ruber_only_denovo_outfiles` directory and open the `ruber_only_denovo_stats.txt` file it in the text editor.\n",
    "\n",
    "\n",
    "There should be about 2498 loci assembled and retained in the assembly (last column of row `total_filtered_loci`):\n",
    "\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Click to show expected ipyrad summary</summary>\n",
    "  <img src=\"images/recovered_loci.png\" width=50% />\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "If we scroll down a bit in the table `The number of loci recovered for each Sample`, we can see that SD_Field_0506 has almost no loci shared with other samples, and SD_Field_1453 has only about half as many loci as most samples. We’ll want to remove these samples before moving on. \n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>Click to show expected loci per sample</summary>\n",
    "  <img src=\"images/drop_samples.png\" width=50% />\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Note that SD_Field_0506 is an obviously failed sample, but for SD_Field_1453, you would likely want to try out some preliminary downstream analyses with and without this sample – I’ve already analyzed these data and decided it’s best to remove it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d973e6fa-16da-4f6b-9cc5-122ca373fdee",
   "metadata": {},
   "source": [
    "## Branch to remove low data samples\n",
    "\n",
    "Start by making a new names file to exclude SD_Field_0506 and SD_Field_1453 called `names_ruber_reduced.txt`. To do this, we can use a `grep` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76572e48-3f5e-476b-a3bd-d8a2591afda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! grep -v -E \"\\bSD_Field_0506\\b|\\bSD_Field_1453\\b\" radseq_cloud/ruber_data/names_ruber_all.txt > radseq_cloud/ruber_data/names_ruber_reduced.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b656ce-dca0-4d22-9b1c-72faa441f7ac",
   "metadata": {},
   "source": [
    "- If you look at the `names_ruber_reduced.txt` file, it should be down to 33 lines (samples)\n",
    "\n",
    "\n",
    "Then do the branching and run step 7 on that new branch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef23bd8-7fba-4ede-938b-2d9e373a92a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# branch\n",
    "! ipyrad -p params-ruber_only_denovo.txt -b ruber_reduced_denovo radseq_cloud/ruber_data/names_ruber_reduced.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7db89-4f08-49cb-bdc6-f5c93b15a642",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run step 7\n",
    "! ipyrad -p params-ruber_reduced_denovo.txt -s 7 -c 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16474d50-4c45-4c99-8fa8-31c975143f2b",
   "metadata": {},
   "source": [
    "Look at the stats for the new assembly in `ipyrad_out/ruber_reduced_denovo_outfiles/ruber_reduced_denovo_stats.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3017d-0fd6-429b-8ad1-18d262aa2ed5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_quiz(\"quizzes/submodule_1/quiz2.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b75ac23-e024-49de-a567-a43a41b95a13",
   "metadata": {
    "tags": []
   },
   "source": [
    "You should now see a slight decrease in the number of loci, but pretty good coverage across individuals, with no single sample having maassive amounts of missing data. This looks like a good dataset to move forward with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94db5a05-4ebf-4d7d-9cfc-fdb03d947349",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_quiz(\"quizzes/submodule_1/quiz3.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a054a01-aa43-458f-a8c8-d3bd7a8f8170",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have all sorts of variously formatted data files in the output directory. This data will all be saved in your Google Cloud instance and you can access it from the other notebooks, so long as you don't delete your instance. If you are going to delete your instance, you should first download your files or add them to a bucket. \n",
    "\n",
    "\n",
    "This is an example of how you could create a bucket and upload the results from ipyrad into it, and then also copy the file with coordinates into it. `your-new-bucket` is a placeholder for whatever you would actually call your bucket. Keep in mind that if you create a bucket and put data into it, there will be a cost associated with that storage as long as it persists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a81568-6eb2-4a3f-8f8f-ca7706714f10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a new bucket\n",
    "# ! gsutil mb -l us-east4 gs://your-new-bucket\n",
    "\n",
    "# Copy the ipyrad output\n",
    "# ! gsutil -m cp /home/jupyter/RADseq_cloud_learn/ipyrad_out/ruber_reduced_denovo_outfiles/*  gs://your-new-bucket/\n",
    "\n",
    "# Copy over the file of locality coordinates for each sample\n",
    "# ! gsutil cp /home/jupyter/RADseq_cloud_learn/radseq_cloud/ruber_data/Localities.csv gs://your-new-bucket/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e5101d-bb93-4849-bd7a-75cc61a84f5a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrated how to use ipyrad to assemble raw ddRADseq data. We showed to remove samples that are not part of the focal group. We also showed how to identify and remove individual samples with large amounts of missing data and how to filter loci by missing data per sample for each locus (parameter 21 `min_samples_locus`). Keep in mind that we have only grazed the surface of ipyrad functionality and the parameters that we used here are not global appropriate for all datasets.\n",
    "\n",
    "<br>\n",
    "\n",
    "# Cleanup\n",
    "\n",
    "If you are not immediately moving on to the next notebook, shut down your GCP instance to prevent being charged while it sits idle."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m127",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m127"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "micromamba-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
